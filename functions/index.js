/**
 * Firebase Functions - EGT Auto Scraper
 * Point d'entrÃ©e principal pour les fonctions Firebase
 */

const functions = require('firebase-functions');
const admin = require('firebase-admin');

// Initialiser Firebase Admin (nÃ©cessaire pour les fonctions)
admin.initializeApp();

// Imports des modules de scraping
const { scrapeEGTPage, filterNewSessions } = require('./scraper/egt-scraper');
const { downloadMultipleSessions } = require('./scraper/download-manager');
const { getExistingSessions, saveMultipleSessions, updateProcessedData } = require('./firestore/session-storage');
const { createScrapingLog, updateScrapingLog, createErrorLog } = require('./firestore/logs-collection');

/**
 * Fonction principale de scraping EGT
 * ExÃ©cutÃ©e automatiquement toutes les heures ou manuellement
 */
async function runEGTScraping(trigger = 'scheduled') {
    const startTime = Date.now();
    let logId = null;
    
    try {
        console.log(`ğŸš€ DÃ©but du scraping EGT (trigger: ${trigger})`);
        
        // CrÃ©er le log initial
        logId = await createScrapingLog({
            status: 'started',
            trigger: trigger
        });
        
        // 1. Scraper la page EGT
        console.log('ğŸ“‹ Ã‰tape 1: Scraping de la page EGT...');
        const scrapedSessions = await scrapeEGTPage();
        
        // 2. RÃ©cupÃ©rer les sessions existantes
        console.log('ğŸ“‹ Ã‰tape 2: RÃ©cupÃ©ration des sessions existantes...');
        const existingSessions = await getExistingSessions();
        
        // 3. Filtrer les nouvelles sessions
        console.log('ğŸ“‹ Ã‰tape 3: Filtrage des nouvelles sessions...');
        const newSessions = filterNewSessions(scrapedSessions, existingSessions);
        
        // 4. TÃ©lÃ©charger les nouvelles sessions
        let downloadResults = { successful: [], failed: [], summary: { total: 0, successful: 0, failed: 0, successRate: 0 } };
        
        if (newSessions.length > 0) {
            console.log('ğŸ“‹ Ã‰tape 4: TÃ©lÃ©chargement des nouvelles sessions...');
            downloadResults = await downloadMultipleSessions(newSessions, 5000); // 5 secondes entre chaque
        } else {
            console.log('ğŸ“‹ Ã‰tape 4: Aucune nouvelle session Ã  tÃ©lÃ©charger');
        }
        
        // 5. Sauvegarder les sessions tÃ©lÃ©chargÃ©es
        let saveResults = { saved: 0, failed: 0, errors: [] };
        
        if (downloadResults.successful.length > 0) {
            console.log('ğŸ“‹ Ã‰tape 5: Sauvegarde des sessions tÃ©lÃ©chargÃ©es...');
            const sessionsToSave = downloadResults.successful.map(item => item.data);
            saveResults = await saveMultipleSessions(sessionsToSave);
        } else {
            console.log('ğŸ“‹ Ã‰tape 5: Aucune session Ã  sauvegarder');
        }
        
        // 6. Mettre Ã  jour les donnÃ©es traitÃ©es (si nouvelles sessions)
        if (saveResults.saved > 0) {
            console.log('ğŸ“‹ Ã‰tape 6: Mise Ã  jour des donnÃ©es traitÃ©es...');
            // TODO: IntÃ©grer la logique de processSessionData du frontend
            // Pour l'instant, on laisse le frontend s'occuper de Ã§a
            console.log('âš ï¸ Mise Ã  jour des donnÃ©es traitÃ©es Ã  implÃ©menter');
        }
        
        // Calculer le temps d'exÃ©cution
        const executionTime = Date.now() - startTime;
        
        // Mettre Ã  jour le log avec les rÃ©sultats
        await updateScrapingLog(logId, {
            status: 'completed',
            executionTime: executionTime,
            
            scraping: {
                totalSessionsFound: scrapedSessions.length,
                newSessionsFound: newSessions.length,
                existingSessionsIgnored: scrapedSessions.length - newSessions.length
            },
            
            downloads: {
                total: downloadResults.summary.total,
                successful: downloadResults.summary.successful,
                failed: downloadResults.summary.failed,
                successRate: downloadResults.summary.successRate
            },
            
            sessions: {
                downloaded: downloadResults.successful.map(item => item.sessionId),
                failed: downloadResults.failed.map(item => item.sessionId)
            },
            
            saveResults: saveResults
        });
        
        console.log(`âœ… Scraping EGT terminÃ© avec succÃ¨s en ${executionTime}ms`);
        console.log(`ğŸ“Š RÃ©sumÃ©: ${downloadResults.summary.successful} tÃ©lÃ©chargements rÃ©ussis, ${downloadResults.summary.failed} Ã©checs`);
        
        return {
            success: true,
            executionTime: executionTime,
            summary: {
                scraped: scrapedSessions.length,
                new: newSessions.length,
                downloaded: downloadResults.summary.successful,
                saved: saveResults.saved,
                failed: downloadResults.summary.failed
            }
        };
        
    } catch (error) {
        const executionTime = Date.now() - startTime;
        console.error('âŒ Erreur lors du scraping EGT:', error);
        
        // CrÃ©er un log d'erreur
        await createErrorLog(error.message, trigger);
        
        // Mettre Ã  jour le log existant si il existe
        if (logId) {
            await updateScrapingLog(logId, {
                status: 'failed',
                executionTime: executionTime,
                errors: [error.message]
            });
        }
        
        throw error;
    }
}

/**
 * Fonction Firebase dÃ©clenchÃ©e par un cron job (toutes les heures)
 */
exports.scrapeEGTHourly = functions.pubsub
    .schedule('0 * * * *') // Toutes les heures Ã  la minute 0
    .timeZone('America/Montreal')
    .onRun(async (context) => {
        console.log('â° DÃ©clenchement automatique du scraping EGT');
        return await runEGTScraping('scheduled');
    });

/**
 * Fonction Firebase pour dÃ©clenchement manuel (HTTP)
 */
exports.scrapeEGTManual = functions.https.onRequest(async (req, res) => {
    // Ajouter les headers CORS
    res.set('Access-Control-Allow-Origin', '*');
    res.set('Access-Control-Allow-Methods', 'GET, POST, OPTIONS');
    res.set('Access-Control-Allow-Headers', 'Content-Type, Authorization');
    
    // GÃ©rer les requÃªtes OPTIONS (preflight)
    if (req.method === 'OPTIONS') {
        res.status(204).send('');
        return;
    }
    
    // VÃ©rifier la mÃ©thode HTTP
    if (req.method !== 'POST') {
        return res.status(405).json({ error: 'MÃ©thode non autorisÃ©e. Utilisez POST.' });
    }
    
    // VÃ©rifier l'authentification (optionnel, pour sÃ©curiser)
    const authHeader = req.headers.authorization;
    if (!authHeader || !authHeader.startsWith('Bearer ')) {
        return res.status(401).json({ error: 'Authentification requise' });
    }
    
    try {
        console.log('ğŸ¯ DÃ©clenchement manuel du scraping EGT');
        const result = await runEGTScraping('manual');
        
        res.status(200).json({
            success: true,
            message: 'Scraping EGT exÃ©cutÃ© avec succÃ¨s',
            result: result
        });
        
    } catch (error) {
        console.error('âŒ Erreur lors du scraping manuel:', error);
        
        res.status(500).json({
            success: false,
            error: error.message,
            message: 'Erreur lors du scraping EGT'
        });
    }
});

/**
 * Fonction Firebase pour rÃ©cupÃ©rer les logs rÃ©cents
 */
exports.getScrapingLogs = functions.https.onRequest(async (req, res) => {
    // Ajouter les headers CORS
    res.set('Access-Control-Allow-Origin', '*');
    res.set('Access-Control-Allow-Methods', 'GET, POST, OPTIONS');
    res.set('Access-Control-Allow-Headers', 'Content-Type, Authorization');
    
    // GÃ©rer les requÃªtes OPTIONS (preflight)
    if (req.method === 'OPTIONS') {
        res.status(204).send('');
        return;
    }
    
    try {
        const { getRecentLogs } = require('./firestore/logs-collection');
        const limit = parseInt(req.query.limit) || 50;
        
        const logs = await getRecentLogs(limit);
        
        res.status(200).json({
            success: true,
            logs: logs
        });
        
    } catch (error) {
        console.error('âŒ Erreur lors de la rÃ©cupÃ©ration des logs:', error);
        
        res.status(500).json({
            success: false,
            error: error.message
        });
    }
});

/**
 * Fonction Firebase pour rÃ©cupÃ©rer les serveurs ACC actifs
 * Proxy pour contourner les restrictions CORS
 */
exports.getACCServers = functions.https.onRequest(async (req, res) => {
    // Ajouter les headers CORS
    res.set('Access-Control-Allow-Origin', '*');
    res.set('Access-Control-Allow-Methods', 'GET, POST, OPTIONS');
    res.set('Access-Control-Allow-Headers', 'Content-Type, Authorization');
    
    // GÃ©rer les requÃªtes OPTIONS (preflight)
    if (req.method === 'OPTIONS') {
        res.status(204).send('');
        return;
    }
    
    try {
        const { track, limit = 25 } = req.query;
        
        if (!track) {
            return res.status(400).json({
                success: false,
                error: 'Le paramÃ¨tre track est requis'
            });
        }
        
        // URL de l'API ACC Status
        const url = `https://acc-status.jonatan.net/api/v2/acc/servers?limit=${limit}&skip=0&sort[drivers]=-1&mode=public&track=${track}&safety_rating[min]=0&safety_rating[max]=100&offline=false`;
        
        console.log(`ğŸ® RÃ©cupÃ©ration des serveurs ACC pour le circuit: ${track}`);
        
        // Faire l'appel HTTP depuis le serveur
        const https = require('https');
        const http = require('http');
        const axios = require('axios');
        
        const response = await axios.get(url);
        
        if (response.status !== 200) {
            throw new Error(`Erreur HTTP: ${response.status}`);
        }
        
        // Filtrer pour garder seulement les serveurs avec des joueurs
        const servers = response.data.servers || [];
        const activeServers = servers
            .filter(server => server.drivers > 0)
            .slice(0, 3)
            .map(server => ({
                name: server.name ? server.name.substring(0, 20) : 'Serveur',
                drivers: server.drivers,
                max_drivers: server.max_drivers || 30,
                sessions: server.sessions || []
            }));
        
        console.log(`âœ… ${activeServers.length} serveur(s) trouvÃ©(s) pour ${track}`);
        
        res.status(200).json({
            success: true,
            servers: activeServers
        });
        
    } catch (error) {
        console.error('âŒ Erreur lors de la rÃ©cupÃ©ration des serveurs ACC:', error);
        
        res.status(500).json({
            success: false,
            error: error.message
        });
    }
});

/**
 * Fonction de test pour dÃ©veloppement local
 */
exports.testScraping = functions.https.onRequest(async (req, res) => {
    try {
        console.log('ğŸ§ª Test du scraping EGT');
        const result = await runEGTScraping('test');
        
        res.status(200).json({
            success: true,
            message: 'Test du scraping rÃ©ussi',
            result: result
        });
        
    } catch (error) {
        console.error('âŒ Erreur lors du test:', error);
        
        res.status(500).json({
            success: false,
            error: error.message
        });
    }
});
